{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importa√ß√£o Bibliotecas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = '../../data/'\n",
    "SEED = 42\n",
    "TARGET_COL = \"default.payment.next.month\"\n",
    "URI = \"http://localhost:5000\"\n",
    "TEST_SIZE = 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O c√≥digo abaixo define onde estar√° dispon√≠vel o servi√ßo de model tracking, neste caso o MLflow, que est√° a correr localmente na porta 5000 (http://localhost:5000). Este servi√ßo ser√° respons√°vel por guardar os registos do treino dos modelos, incluindo par√¢metros, m√©tricas, artefactos e outros dados relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "mlflow.set_tracking_uri(URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta c√©lula define o nome da experi√™ncia no MLflow nesse caso \"Rumos Bank Lending\". Atrav√©s da experi√™ncia ser√° possivel  agrupar todas as execu√ß√µes (runs) relacionadas com um determinado objectivo ou projecto, facilitando a compara√ß√£o de resultados entre diferentes modelos, configura√ß√µes ou vers√µes de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/395285683720049485', creation_time=1744151061274, experiment_id='395285683720049485', last_update_time=1744151061274, lifecycle_stage='active', name='Rumos Bank Lending', tags={}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Rumos Bank Lending\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta c√©lula carrega os dados a partir do ficheiro lending_data.csv, localizado no caminho definido por ROOT_PATH. Em seguida, seleciona aleatoriamente todas as linhas do DataFrame utilizando uma seed fixa (SEED) para garantir reprodutibilidade. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ROOT_PATH + 'lending_data.csv')\n",
    "df = df.sample(frac=0.01, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A c√©lula abaixo divide o conjunto de dados df em dois subconjuntos: conjunto de treino (train_set) e conjunto de teste (test_set). A divis√£o √© feita de forma aleat√≥ria, com 20% dos dados reservados para teste e os restantes 80% para treino. A utiliza√ß√£o da seed (SEED) garante que a divis√£o √© reprodut√≠vel ‚Äî ou seja, ser√° sempre igual em diferentes execu√ß√µes do c√≥digo. Esta separa√ß√£o √© essencial para avaliar o desempenho dos modelos com dados que n√£o foram usados durante o treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(df, test_size = TEST_SIZE, random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta c√©lula separa as features (vari√°veis independentes) e o target (vari√°vel dependente) tanto para o conjunto de treino como para o conjunto de teste. A coluna 'default.payment.next.month' representa a vari√°vel que se pretende prever (se o cliente ir√° ou n√£o entrar em incumprimento no m√™s seguinte), sendo por isso atribu√≠da √†s vari√°veis alvo y_train e y_test. As restantes colunas s√£o utilizadas como input (X_train e X_test) para treinar e testar os modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.drop(['default.payment.next.month'], axis = 'columns')\n",
    "y_train = train_set['default.payment.next.month']\n",
    "\n",
    "X_test = test_set.drop(['default.payment.next.month'], axis = 1)\n",
    "y_test = test_set['default.payment.next.month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar datasets, modelos, artefactos, m√©tricas e parametros da run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta c√©lula converte os conjuntos de treino e teste (train_set e test_set) em objectos mlflow.data, utilizando a fun√ß√£o from_pandas. Isto permite que os dados sejam registados no MLflow de forma estruturada, com mmetadados adicionais, como a origem (source=\"split_from_full_dataset\") e o nome do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PereiraRodrigues\\miniconda3\\envs\\rumos_bank_lending\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:149: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for 'split_from_full_dataset'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\PereiraRodrigues\\miniconda3\\envs\\rumos_bank_lending\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:149: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\PereiraRodrigues\\miniconda3\\envs\\rumos_bank_lending\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:149: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for 'split_from_full_dataset'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\PereiraRodrigues\\miniconda3\\envs\\rumos_bank_lending\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:149: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n"
     ]
    }
   ],
   "source": [
    "# guardar o dataset de treino e de teste associado √† run\n",
    "train_dataset = mlflow.data.from_pandas(train_set, source=\"split_from_full_dataset\", targets=TARGET_COL, name=\"Rumos Bank Lending Dataset\")\n",
    "test_dataset = mlflow.data.from_pandas(test_set, source=\"split_from_full_dataset\", targets=TARGET_COL, name=\"Rumos Bank Lending Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta c√©lula define uma lista chamada models_and_params, que cont√©m os pipelines e os respectivos espa√ßos de procura de hiperpar√¢metros para seis modelos de machine learning: regress√£o log√≠stica, (KNN), √°rvore de decis√£o, (Random Forest), perceptr√£o multicamada (MLP) e (SVC).\n",
    "\n",
    "Cada modelo √© encapsulado num Pipeline que come√ßa com um MinMaxScaler() para normaliza√ß√£o das vari√°veis, garantindo que os dados de entrada est√£o na mesma escala ‚Äî o que √© especialmente importante para algoritmos baseados em dist√¢ncias ou gradientes.\n",
    "\n",
    "Para cada modelo √© tamb√©m definido um dicion√°rio com os hiperpar√¢metros a testar durante o processo de optimiza√ß√£o (por exemplo, valores de C na regress√£o log√≠stica ou n√∫mero de vizinhos no KNN). Esta estrutura ser√° usada posteriormente com GridSearchCV para realizar a afina√ß√£o autom√°tica dos modelos durante o treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_and_params = [\n",
    "\n",
    "    (\"logistic_regression\",\n",
    "     Pipeline([\n",
    "         (\"scaler\", MinMaxScaler()),\n",
    "         (\"Classifier\", LogisticRegression(max_iter=500, solver='lbfgs', random_state=SEED, class_weight='balanced'))\n",
    "     ]),\n",
    "     {\n",
    "         \"Classifier__C\": [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "     }),\n",
    "\n",
    "    (\"knn\",\n",
    "     Pipeline([\n",
    "         (\"scaler\", MinMaxScaler()),\n",
    "         (\"Classifier\", KNeighborsClassifier())\n",
    "     ]),\n",
    "     {\n",
    "         \"Classifier__n_neighbors\": list(range(1, 10))\n",
    "     }),\n",
    "\n",
    "    (\"decision_tree\",\n",
    "     Pipeline([\n",
    "         (\"scaler\", MinMaxScaler()),\n",
    "         (\"Classifier\", tree.DecisionTreeClassifier(random_state=SEED, class_weight='balanced'))\n",
    "     ]),\n",
    "     {\n",
    "         \"Classifier__max_depth\": [3, 6],\n",
    "         \"Classifier__min_samples_split\": [2, 4, 10]\n",
    "     }),\n",
    "\n",
    "    (\"random_forest\",\n",
    "     Pipeline([\n",
    "         (\"scaler\", MinMaxScaler()),\n",
    "         (\"Classifier\", RandomForestClassifier(random_state=SEED, class_weight='balanced'))\n",
    "     ]),\n",
    "     {\n",
    "         \"Classifier__n_estimators\": [10, 100, 300, 1000]\n",
    "     }),\n",
    "\n",
    "    (\"mlp\",\n",
    "     Pipeline([\n",
    "         (\"scaler\", MinMaxScaler()),\n",
    "         (\"Classifier\", MLPClassifier(solver='lbfgs', random_state=SEED, max_iter=1000))\n",
    "     ]),\n",
    "     {\n",
    "         \"Classifier__hidden_layer_sizes\": [(20,), (20, 10), (20, 10, 2)],\n",
    "         \"Classifier__learning_rate_init\": [0.0001, 0.001, 0.01, 0.1]\n",
    "     }),\n",
    "\n",
    "    (\"svc\",\n",
    "     Pipeline([\n",
    "         (\"scaler\", MinMaxScaler()),\n",
    "         (\"Classifier\", SVC(random_state=SEED, class_weight='balanced', gamma='scale', probability=True, verbose=True))\n",
    "     ]),\n",
    "     {\n",
    "         \"Classifier__C\": [0.1, 1, 10],\n",
    "         \"Classifier__kernel\": ['rbf', 'linear']\n",
    "     })\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O presente bloco de c√≥digo percorre cada um dos modelos definidos anteriormente, treinando-os e registando-os no MLflow. Para cada modelo, inicia-se uma nova execu√ß√£o (run) no MLflow, onde s√£o guardadas informa√ß√µes relevantes como os dados de treino e de teste (atrav√©s dos objetos train_dataset e test_dataset), bem como a seed utilizada para garantir a reprodutibilidade.\n",
    "\n",
    "De seguida, √© utilizado o GridSearchCV com valida√ß√£o cruzada de 5 folds para encontrar a melhor combina√ß√£o de hiperpar√¢metros com base na m√©trica de accuracy. Ap√≥s o treino, √© registado o tempo total de execu√ß√£o e identificado o melhor modelo encontrado.\n",
    "\n",
    "Este modelo √© ent√£o guardado no MLflow, e as respetivas experi√™ncias. Por fim, s√£o tamb√©m registados os melhores par√¢metros encontrados, a pontua√ß√£o m√©dia obtida na valida√ß√£o cruzada e o tempo de treino em segundos. Este processo permite treinar e comparar v√°rios modelos de forma estruturada e facilmente rastre√°vel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PereiraRodrigues\\miniconda3\\envs\\rumos_bank_lending\\Lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando modelo e guardando todos os logs em MlFlow: logistic_regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/10 17:40:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'logistic_regression' already exists. Creating a new version of this model...\n",
      "2025/04/10 17:40:09 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: logistic_regression, version 22\n",
      "Created version '22' of model 'logistic_regression'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'logistic_regression' guardado  MLflow.\n",
      "üèÉ View run Ml Model Run - pipeline at: http://localhost:5000/#/experiments/395285683720049485/runs/34f05a14baa846019fd4a5faad1f94f3\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/395285683720049485\n",
      "Treinando modelo e guardando todos os logs em MlFlow: knn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/10 17:40:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'knn' already exists. Creating a new version of this model...\n",
      "2025/04/10 17:40:15 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: knn, version 22\n",
      "Created version '22' of model 'knn'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'knn' guardado  MLflow.\n",
      "üèÉ View run Ml Model Run - pipeline at: http://localhost:5000/#/experiments/395285683720049485/runs/7beb1a757d4b434f8f59bd81698d6f98\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/395285683720049485\n",
      "Treinando modelo e guardando todos os logs em MlFlow: decision_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/10 17:40:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'decision_tree' already exists. Creating a new version of this model...\n",
      "2025/04/10 17:40:19 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: decision_tree, version 17\n",
      "Created version '17' of model 'decision_tree'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'decision_tree' guardado  MLflow.\n",
      "üèÉ View run Ml Model Run - pipeline at: http://localhost:5000/#/experiments/395285683720049485/runs/660bd2ab4c4c460ab4d59e1e62326c4c\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/395285683720049485\n",
      "Treinando modelo e guardando todos os logs em MlFlow: random_forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/10 17:40:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'random_forest' already exists. Creating a new version of this model...\n",
      "2025/04/10 17:40:34 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest, version 14\n",
      "Created version '14' of model 'random_forest'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'random_forest' guardado  MLflow.\n",
      "üèÉ View run Ml Model Run - pipeline at: http://localhost:5000/#/experiments/395285683720049485/runs/ca500ce8639442778e722efbe4e92f86\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/395285683720049485\n",
      "Treinando modelo e guardando todos os logs em MlFlow: mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/10 17:40:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'mlp' already exists. Creating a new version of this model...\n",
      "2025/04/10 17:40:53 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: mlp, version 14\n",
      "Created version '14' of model 'mlp'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'mlp' guardado  MLflow.\n",
      "üèÉ View run Ml Model Run - pipeline at: http://localhost:5000/#/experiments/395285683720049485/runs/3cbef6ead9834f429cab4e041ab455a0\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/395285683720049485\n",
      "Treinando modelo e guardando todos os logs em MlFlow: svc\n",
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/10 17:40:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'svc' already exists. Creating a new version of this model...\n",
      "2025/04/10 17:40:58 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: svc, version 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'svc' guardado  MLflow.\n",
      "üèÉ View run Ml Model Run - pipeline at: http://localhost:5000/#/experiments/395285683720049485/runs/54642a7a22444937b1dd383ccc78a91b\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/395285683720049485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '7' of model 'svc'.\n"
     ]
    }
   ],
   "source": [
    "for model_name, pipeline, param_grid in models_and_params:\n",
    "\n",
    "    # Iniciar run no MlFlow\n",
    "    run = mlflow.start_run(run_name=\"Ml Model Run - pipeline\")\n",
    "    RUN_ID = run.info.run_uuid\n",
    "\n",
    "    \n",
    "    # Guardar Informa√ß√£o Dataset de treino e de teste associado √† run\n",
    "    mlflow.log_input(train_dataset, context=\"train\")\n",
    "    mlflow.log_input(test_dataset, context=\"test\")\n",
    "\n",
    "    # Guardar parametros seed  e text_size utilizado como parametro\n",
    "    mlflow.log_param(\"seed\", SEED)\n",
    "    mlflow.log_param(\"test size\", TEST_SIZE)\n",
    "\n",
    "\n",
    "    print(f\"Treinando modelo e guardando todos os logs em MlFlow: {model_name}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # GridSearchCV para encontrar os melhores par√¢metros\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time  # tempo em segundos\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    #Guardar Log do modelo no MLflow\n",
    "    mlflow.sklearn.log_model(\n",
    "            sk_model=best_model,\n",
    "            artifact_path=model_name,\n",
    "            registered_model_name=model_name\n",
    "    )\n",
    "\n",
    "    # Guardar Log dos par√¢metros e m√©tricas do modelo\n",
    "    mlflow.log_params(grid_search.best_params_)\n",
    "    mlflow.log_metric(\"best_cv_score\", grid_search.best_score_)\n",
    "    mlflow.log_metric(\"training_time_sec\", elapsed_time)  # tempo registado\n",
    "\n",
    "    print(f\"Modelo '{model_name}' guardado  MLflow.\")\n",
    "    mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
