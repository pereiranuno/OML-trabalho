{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação Bibliotecas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = '../../data/'\n",
    "SEED = 42\n",
    "TARGET_COL = \"default.payment.next.month\"\n",
    "URI = \"http://localhost:5000\"\n",
    "TEST_SIZE = 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código abaixo define onde estará disponível o serviço de model tracking, neste caso o MLflow, que está a correr localmente na porta 5000 (http://localhost:5000). Este serviço será responsável por guardar os registos do treino dos modelos, incluindo parâmetros, métricas, artefactos e outros dados relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "mlflow.set_tracking_uri(URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta célula define o nome da experiência no MLflow nesse caso \"Rumos Bank Lending\". Através da experiência será possivel  agrupar todas as execuções (runs) relacionadas com um determinado objectivo ou projecto, facilitando a comparação de resultados entre diferentes modelos, configurações ou versões de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/395285683720049485', creation_time=1744151061274, experiment_id='395285683720049485', last_update_time=1744151061274, lifecycle_stage='active', name='Rumos Bank Lending', tags={}>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Rumos Bank Lending\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta célula carrega os dados a partir do ficheiro lending_data.csv, localizado no caminho definido por ROOT_PATH. Em seguida, seleciona aleatoriamente todas as linhas do DataFrame utilizando uma seed fixa (SEED) para garantir reprodutibilidade. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ROOT_PATH + 'lending_data.csv')\n",
    "df = df.sample(frac=0.01, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A célula abaixo divide o conjunto de dados df em dois subconjuntos: conjunto de treino (train_set) e conjunto de teste (test_set). A divisão é feita de forma aleatória, com 20% dos dados reservados para teste e os restantes 80% para treino. A utilização da seed (SEED) garante que a divisão é reprodutível — ou seja, será sempre igual em diferentes execuções do código. Esta separação é essencial para avaliar o desempenho dos modelos com dados que não foram usados durante o treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(df, test_size = TEST_SIZE, random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta célula separa as features (variáveis independentes) e o target (variável dependente) tanto para o conjunto de treino como para o conjunto de teste. A coluna 'default.payment.next.month' representa a variável que se pretende prever (se o cliente irá ou não entrar em incumprimento no mês seguinte), sendo por isso atribuída às variáveis alvo y_train e y_test. As restantes colunas são utilizadas como input (X_train e X_test) para treinar e testar os modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.drop(['default.payment.next.month'], axis = 'columns')\n",
    "y_train = train_set['default.payment.next.month']\n",
    "\n",
    "X_test = test_set.drop(['default.payment.next.month'], axis = 1)\n",
    "y_test = test_set['default.payment.next.month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar datasets, modelos, artefactos, métricas e parametros da run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta célula converte os conjuntos de treino e teste (train_set e test_set) em objectos mlflow.data, utilizando a função from_pandas. Isto permite que os dados sejam registados no MLflow de forma estruturada, com mmetadados adicionais, como a origem (source=\"split_from_full_dataset\") e o nome do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PereiraRodrigues\\miniconda3\\envs\\rumos_bank_lending\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:149: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for 'split_from_full_dataset'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\PereiraRodrigues\\miniconda3\\envs\\rumos_bank_lending\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:149: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\PereiraRodrigues\\miniconda3\\envs\\rumos_bank_lending\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:149: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for 'split_from_full_dataset'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\Users\\PereiraRodrigues\\miniconda3\\envs\\rumos_bank_lending\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:149: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n"
     ]
    }
   ],
   "source": [
    "# guardar o dataset de treino e de teste associado à run\n",
    "train_dataset = mlflow.data.from_pandas(train_set, source=\"split_from_full_dataset\", targets=TARGET_COL, name=\"Rumos Bank Lending Dataset\")\n",
    "test_dataset = mlflow.data.from_pandas(test_set, source=\"split_from_full_dataset\", targets=TARGET_COL, name=\"Rumos Bank Lending Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta célula define uma lista chamada models_and_params, que contém os pipelines e os respectivos espaços de procura de hiperparâmetros para seis modelos de machine learning: regressão logística, (KNN), árvore de decisão, (Random Forest), perceptrão multicamada (MLP) e (SVC).\n",
    "\n",
    "Cada modelo é encapsulado num Pipeline que começa com um MinMaxScaler() para normalização das variáveis, garantindo que os dados de entrada estão na mesma escala — o que é especialmente importante para algoritmos baseados em distâncias ou gradientes.\n",
    "\n",
    "Para cada modelo é também definido um dicionário com os hiperparâmetros a testar durante o processo de optimização (por exemplo, valores de C na regressão logística ou número de vizinhos no KNN). Esta estrutura será usada posteriormente com GridSearchCV para realizar a afinação automática dos modelos durante o treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_and_params = [\n",
    "\n",
    "    (\"logistic_regression\",\n",
    "     Pipeline([\n",
    "         (\"scaler\", MinMaxScaler()),\n",
    "         (\"Classifier\", LogisticRegression(max_iter=500, solver='lbfgs', random_state=SEED, class_weight='balanced'))\n",
    "     ]),\n",
    "     {\n",
    "         \"Classifier__C\": [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "     }),\n",
    "\n",
    "    (\"knn\",\n",
    "     Pipeline([\n",
    "         (\"scaler\", MinMaxScaler()),\n",
    "         (\"Classifier\", KNeighborsClassifier())\n",
    "     ]),\n",
    "     {\n",
    "         \"Classifier__n_neighbors\": list(range(1, 10))\n",
    "     }),\n",
    "\n",
    "    (\"decision_tree\",\n",
    "     Pipeline([\n",
    "         (\"scaler\", MinMaxScaler()),\n",
    "         (\"Classifier\", tree.DecisionTreeClassifier(random_state=SEED, class_weight='balanced'))\n",
    "     ]),\n",
    "     {\n",
    "         \"Classifier__max_depth\": [3, 6],\n",
    "         \"Classifier__min_samples_split\": [2, 4, 10]\n",
    "     }),\n",
    "\n",
    "    (\"random_forest\",\n",
    "     Pipeline([\n",
    "         (\"scaler\", MinMaxScaler()),\n",
    "         (\"Classifier\", RandomForestClassifier(random_state=SEED, class_weight='balanced'))\n",
    "     ]),\n",
    "     {\n",
    "         \"Classifier__n_estimators\": [10, 100, 300, 1000]\n",
    "     }),\n",
    "\n",
    "    (\"mlp\",\n",
    "     Pipeline([\n",
    "         (\"scaler\", MinMaxScaler()),\n",
    "         (\"Classifier\", MLPClassifier(solver='lbfgs', random_state=SEED, max_iter=1000))\n",
    "     ]),\n",
    "     {\n",
    "         \"Classifier__hidden_layer_sizes\": [(20,), (20, 10), (20, 10, 2)],\n",
    "         \"Classifier__learning_rate_init\": [0.0001, 0.001, 0.01, 0.1]\n",
    "     }),\n",
    "\n",
    "    (\"svc\",\n",
    "     Pipeline([\n",
    "         (\"scaler\", MinMaxScaler()),\n",
    "         (\"Classifier\", SVC(random_state=SEED, class_weight='balanced', gamma='scale', probability=True, verbose=True))\n",
    "     ]),\n",
    "     {\n",
    "         \"Classifier__C\": [0.1, 1, 10],\n",
    "         \"Classifier__kernel\": ['rbf', 'linear']\n",
    "     })\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O presente bloco de código percorre cada um dos modelos definidos anteriormente, treinando-os e registando-os no MLflow. Para cada modelo, inicia-se uma nova execução (run) no MLflow, onde são guardadas informações relevantes como os dados de treino e de teste (através dos objetos train_dataset e test_dataset), bem como a seed utilizada para garantir a reprodutibilidade.\n",
    "\n",
    "De seguida, é utilizado o GridSearchCV com validação cruzada de 5 folds para encontrar a melhor combinação de hiperparâmetros com base na métrica de accuracy. Após o treino, é registado o tempo total de execução e identificado o melhor modelo encontrado.\n",
    "\n",
    "Este modelo é então guardado no MLflow, e as respetivas experiências. Por fim, são também registados os melhores parâmetros encontrados, a pontuação média obtida na validação cruzada e o tempo de treino em segundos. Este processo permite treinar e comparar vários modelos de forma estruturada e facilmente rastreável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PereiraRodrigues\\miniconda3\\envs\\rumos_bank_lending\\Lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando modelo e guardando todos os logs em MlFlow: logistic_regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/10 17:55:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'logistic_regression' already exists. Creating a new version of this model...\n",
      "2025/04/10 17:55:04 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: logistic_regression, version 25\n",
      "Created version '25' of model 'logistic_regression'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'logistic_regression' guardado  MLflow.\n",
      "🏃 View run Ml Model Run logistic_regression- pipeline at: http://localhost:5000/#/experiments/395285683720049485/runs/50462057b45e4a18acfcc76f7e103a94\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/395285683720049485\n",
      "Treinando modelo e guardando todos os logs em MlFlow: knn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/10 17:55:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'knn' already exists. Creating a new version of this model...\n",
      "2025/04/10 17:55:10 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: knn, version 25\n",
      "Created version '25' of model 'knn'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'knn' guardado  MLflow.\n",
      "🏃 View run Ml Model Run knn- pipeline at: http://localhost:5000/#/experiments/395285683720049485/runs/aecb53d85fa84497bf1e4fdbf2268875\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/395285683720049485\n",
      "Treinando modelo e guardando todos os logs em MlFlow: decision_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/10 17:55:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'decision_tree' already exists. Creating a new version of this model...\n",
      "2025/04/10 17:55:18 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: decision_tree, version 20\n",
      "Created version '20' of model 'decision_tree'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'decision_tree' guardado  MLflow.\n",
      "🏃 View run Ml Model Run decision_tree- pipeline at: http://localhost:5000/#/experiments/395285683720049485/runs/94d58a58972441c6aa7ba76f0e81395c\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/395285683720049485\n",
      "Treinando modelo e guardando todos os logs em MlFlow: random_forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/10 17:56:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'random_forest' already exists. Creating a new version of this model...\n",
      "2025/04/10 17:56:39 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest, version 17\n",
      "Created version '17' of model 'random_forest'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'random_forest' guardado  MLflow.\n",
      "🏃 View run Ml Model Run random_forest- pipeline at: http://localhost:5000/#/experiments/395285683720049485/runs/def8a54e19434fa189a0d16297365b30\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/395285683720049485\n",
      "Treinando modelo e guardando todos os logs em MlFlow: mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/10 17:56:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'mlp' already exists. Creating a new version of this model...\n",
      "2025/04/10 17:57:00 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: mlp, version 17\n",
      "Created version '17' of model 'mlp'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'mlp' guardado  MLflow.\n",
      "🏃 View run Ml Model Run mlp- pipeline at: http://localhost:5000/#/experiments/395285683720049485/runs/80aa1f603c154e178f7de5d80fd0cb82\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/395285683720049485\n",
      "Treinando modelo e guardando todos os logs em MlFlow: svc\n",
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/10 17:57:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'svc' already exists. Creating a new version of this model...\n",
      "2025/04/10 17:57:05 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: svc, version 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'svc' guardado  MLflow.\n",
      "🏃 View run Ml Model Run svc- pipeline at: http://localhost:5000/#/experiments/395285683720049485/runs/27c94d504bb846bca7461cd030716f24\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/395285683720049485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '10' of model 'svc'.\n"
     ]
    }
   ],
   "source": [
    "for model_name, pipeline, param_grid in models_and_params:\n",
    "\n",
    "    # Iniciar run no MlFlow\n",
    "    run = mlflow.start_run(run_name=\"Ml Model Run \"+model_name+ \"- pipeline\")\n",
    "    RUN_ID = run.info.run_uuid\n",
    "\n",
    "    \n",
    "    # Guardar Informação Dataset de treino e de teste associado à run\n",
    "    mlflow.log_input(train_dataset, context=\"train\")\n",
    "    mlflow.log_input(test_dataset, context=\"test\")\n",
    "\n",
    "    # Guardar parametros seed  e text_size utilizado como parametro\n",
    "    mlflow.log_param(\"seed\", SEED)\n",
    "    mlflow.log_param(\"test size\", TEST_SIZE)\n",
    "\n",
    "\n",
    "    print(f\"Treinando modelo e guardando todos os logs em MlFlow: {model_name}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # GridSearchCV para encontrar os melhores parâmetros\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time  # tempo em segundos\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    #Guardar Log do modelo no MLflow\n",
    "    mlflow.sklearn.log_model(\n",
    "            sk_model=best_model,\n",
    "            artifact_path=model_name,\n",
    "            registered_model_name=model_name\n",
    "    )\n",
    "\n",
    "    # Guardar Log dos parâmetros e métricas do modelo\n",
    "    mlflow.log_params(grid_search.best_params_)\n",
    "    mlflow.log_metric(\"best_cv_score\", grid_search.best_score_)\n",
    "    mlflow.log_metric(\"training_time_sec\", elapsed_time)  # tempo registado\n",
    "\n",
    "    print(f\"Modelo '{model_name}' guardado  MLflow.\")\n",
    "    mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
