# Documenta√ß√£o do Projeto - Rumos Bank Lending Prediction


## Rumos Bank Going Live
Este projeto responde ao desafio proposto pelo Rumos Bank, que visa desenvolver uma solu√ß√£o de machine learning capaz de prever clientes que poder√£o falhar no cumprimento dos prazos de pagamento de cr√©dito.

A prioridade do banco √© garantir que a transi√ß√£o dos resultados explorat√≥rios para produ√ß√£o √© feita de forma eficiente e automatizada, evitando demoras como em experi√™ncias anteriores.


> [!IMPORTANT]
> Esta sec√ß√£o cont√©m observa√ß√µes relevantes para garantir a correta execu√ß√£o do projeto.
> A imagem Docker do servi√ßo encontra-se publicada de forma p√∫blica no GitHub Container Registry (GHCR).
> üîó Imagem: `ghcr.io/pereiranuno/bank_lending_prediction_service:latest`
> O servi√ßo n√£o inclui o modelo diretamente na imagem, pois o mesmo √© carregado dinamicamente do **MLflow Tracking Server**, a partir do Model Registry. A vers√£o utilizada √© a `champion` do modelo `random_forest`
> Uma inst√¢ncia do MLflow √© levantado via `docker-compose` e pode ser acedido localmente em http://localhost:5000
> O ficheiro `conda.yaml` define todas as depend√™ncias necess√°rias para reproduzir o ambiente localmente.
> Pode ser usado com:
 ```bash 
    conda env create -f conda.yaml
    conda activate rumos_bank_lending_
```



## Dependencias
- Python 3.10
- FastAPI
- Scikit-learn
- MLflow
- Conda
- Docker
- Pytest
- uvicorn
- ipykernel
- numpy
- pandas
- pydantic
- cloudpickle
- matplotlib
- requests



## Estrutura Projecto
```plaintext
OML-trabalho/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ cicd.yaml
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ app.json
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ lending_data.csv
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ mlflow/
‚îÇ       ‚îú‚îÄ‚îÄ mlflow_model_read.ipynby
‚îÇ       ‚îú‚îÄ‚îÄ mlflow_model_reg.ipynby
‚îÇ   ‚îî‚îÄ‚îÄ rumos_bank_lending_prediction.ipynb
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ app/
‚îÇ       ‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_main.py
‚îÇ   ‚îî‚îÄ‚îÄ test_model.py
‚îú‚îÄ‚îÄ conda.yaml
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Dockerfile.Service
‚îî‚îÄ‚îÄ README.md
```

### Defini√ß√£o Esrutura

- `src/app/main.py` - C√≥digo permite expor modelo ML como um servi√ßo utilizando API FastAPI
- `config/app.json` - Configura√ß√£o do servi√ßo e modelo champion
- `notebooks/rumos_bank_lending_prediction.ipynb` - Notebook explorat√≥rio utilizado para otimizar os modelos existentes
- `notebooks/mlflow/mlflow_model_reg.ipynb` - Notebook que regista os modelos e toda e artefactos e experi√™ncias no model registry
- `notebooks/mlflow/mlflow_model_read.ipynb` - Notebook que testa a leitura do modelo champion e executa uma predi√ß√£o para um conjunto de inputs aleat√≥rios.
- `conda.yaml` - Ambiente conda com a defini√ß√£o das depend√™ncias do projecto
- `Dockerfile.Service` - Dockerfile do servi√ßo do modelo
- `docker-compose.yml` - Orquestra√ß√£o de servi√ßos (MLflow + Modelo como Servi√ßo API)
- `tests/` - Testes unit√°rios da servi√ßo e testes ao  modelo
- `.github/workflows/pipeline.yml` - Pipeline de CI/CD

---


## Reproduzibilidade

Para correr o projeto localmente:

```bash
git clone https://github.com/pereiranuno/OML-trabalho.git
cd OML-trabalho
```
Subir os servi√ßos (MLflow + API)
````docker compose up -d```

Aceder √† API: http://localhost:5002/docs
Aceder ao MLflow: http://localhost:5000

Para testar localmente criar o ambiente atrav√©s
```bash
conda env create -f conda.yaml
conda activate rumos_bank_lending_
pytest
```


## ML Model Registry

Os modelos s√£o treinados e registados com o MLflow, onde a vers√£o com melhor desempenho √© promovida para champion.

O servi√ßo consome o modelo diretamente do MLflow Tracking Server, lendo a configura√ß√£o do modelo em config/app.json a ser utilizado como servi√ßo.

```python
mlflow.set_tracking_uri("http://mlflow-tracking-server:5000")
mlflow.pyfunc.load_model("models:/random_forest@champion")
```

A imagem apresentada mostra a interface do MLflow na aba de das runs feitas para cada modelo. Nesta sec√ß√£o  √© possivel  permite visualizar e comparar execu√ß√µes de treino de diferentes modelos de machine learning realizadas no √¢mbito deste projeto.

Cada linha representa uma execu√ß√£o (run), ou seja, uma inst√¢ncia em que um modelo foi treinado com um determinado conjunto de par√¢metros e dados. A execu√ß√£o √© registada com os seguintes detalhes.

![alt text](utils/pics/experiments.png)


A imagem abaixo mostra o separador ‚ÄúModels‚Äù da interface do MLflow, onde se encontram registados os modelos resultantes dos treinos realizados no projeto Rumos Bank Lending.

Nesta sec√ß√£o, √© poss√≠vel ver todos os modelos que foram registados no Model Registry, juntamente com a respetiva vers√£o mais recente e informa√ß√µes adicionais.

![alt text](utils/pics/models.png)

A imagem apresenta uma visualiza√ß√£o comparativa de 6 execu√ß√µes (runs) de modelos treinados no √¢mbito do projeto, utilizando a funcionalidade de ‚ÄúParallel Coordinates Plot‚Äù do MLflow. Esta ferramenta permite comparar diferentes execu√ß√µes com base em m√©tricas selecionadas, facilitando a an√°lise de desempenho.

Cada linha no gr√°fico representa uma execu√ß√£o, e a sua traject√≥ria liga os valores das duas m√©tricas, training_time_sec: tempo total de treino de cada modelo (em segundos) e best_cv_score: melhor pontua√ß√£o obtida em valida√ß√£o cruzada em accuracy. 

O modelo MLP (Multilayer Perceptron) obteve o melhor desempenho global, com um best_cv_score de 0.821, e um tempo de treino relativamente elevado: 917 segundos (~15.4 minutos).
O Random Forest surge logo a seguir em termos de performance, com best_cv_score de 0.816, mas com uma grande vantagem no tempo de treino, demorando apenas 38.65 segundos.
J√° o modelo SVC (Support Vector Classifier), embora tenha alcan√ßado um score competitivo (0.785), teve um tempo de treino extremamente elevado, de 3338 segundos (~55.8 minutos), o que o torna menos eficiente computacionalmente.
Entre os modelos mais leves, o KNN apresenta uma boa performance (0.808) com apenas 11.42 segundos de treino, o Decision Tree tem best_cv_score de 0.759 e treina em apenas 3.59 segundos e o Logistic Regression foi o mais r√°pido a treinar (2.45 segundos), mas teve o best_cv_score mais baixo: 0.704.~

O Random Forest √© uma excelente escolha em termos de trade-off entre desempenho e efici√™ncia, dai ter sido esolhido como o modelo Champion

![alt text](utils/pics/compare0.png)

O mlflow permite tamb√©m criar gr√°ficos personalizados para as diferentes m√©tricas. Abaixo s√£o apresentados gr√°ficos para as m√©tricas performance acuraccy, e tempo de execu√ß√£o de cada uma das runs dos modelos. .

![alt text](utils/pics/compare1.png)

![alt text](utils/pics/compare2.png)

A imagem abaixo mostra uma tabela comparativa gerada pelo MLflow, onde s√£o analisadas diferentes execu√ß√µes de modelos com base nos par√¢metros utilizados e nas m√©tricas de desempenho obtidas. Esta visualiza√ß√£o √© extremamente √∫til para avaliar o impacto dos hiperpar√¢metros nos resultados dos modelos. 

![alt text](utils/pics/compare3.png)



## Modelo como um servi√ßo

- O modelo treinado encontra-se exposto atrav√©s de uma **API REST criada com FastAPI**.
- O endpoint principal de previs√£o est√° acess√≠vel em: `POST http://localhost:5002/predict_bank_lending`
- A comunica√ß√£o com a API pode ser feita via Postman ou curl.

#### Exemplo de comunica√ß√£o:
**Request:**
```http
POST http://localhost:5002/predict_bank_lending
Content-Type: application/json

{
  "LIMIT_BAL": 2000,
  "SEX": 2,
  "EDUCATION": 1,
  "MARRIAGE": 2,
  "AGE": 26,
  "PAY_0": 1,
  "PAY_2": 2,
  "PAY_3": 2,
  "PAY_4": 2,
  "PAY_5": 2,
  "PAY_6": 2,
  "BILL_AMT1": 1001,
  "BILL_AMT2": 1200,
  "BILL_AMT3": 1300,
  "BILL_AMT4": 1249,
  "BILL_AMT5": 1000,
  "BILL_AMT6": 1000,
  "PAY_AMT1": 1000,
  "PAY_AMT2": 1000,
  "PAY_AMT3": 1000,
  "PAY_AMT4": 1000,
  "PAY_AMT5": 1000,
  "PAY_AMT6": 1000
}
```
**Response:**
```http
{
  "prediction": 0
}
```

## CI/CD

O projeto inclui uma pipeline GitHub Actions que:

1. Clona o reposit√≥rio
2. Constr√≥i os servi√ßos via Docker Compose
3. Cria o ambiente Conda e executa os testes com `pytest`
4. Faz login no GHCR
5. Publica a imagem para o container registry

O acesso √† imagem √© garantido atrav√©s do `GITHUB_TOKEN`, pois o reposit√≥rio est√° devidamente ligado ao package no GHCR com as respetivas permiss√µes.

---


## Autor
Nuno Pereira
github.com/pereiranuno
pereiranuno@gmail.com





